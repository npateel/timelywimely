{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6745d345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from bert import QA\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from fuzzywuzzy import fuzz\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "sys.path.insert(1, '../timelywimely/')\n",
    "import wikiapi\n",
    "from wikiapi import get_wikipedia_revision\n",
    "import requests\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862e3c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcfbcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "list_of_q = []\n",
    "# with gzip.open('../tiny-dev/nq-dev-sample.jsonl.gz') as f:\n",
    "# with gzip.open('../tiny-dev/v1.0-simplified_nq-dev-all.jsonl.gz') as f:\n",
    "with gzip.open('../tiny-dev/v1.0-simplified_simplified-nq-train.jsonl.gz') as f: \n",
    "    for line in tqdm(f):\n",
    "        list_of_q.append(line)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cd6045",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = json.loads(list_of_q[1])\n",
    "start_token = x['annotations'][0]['long_answer']['start_token']\n",
    "end_token = x['annotations'][0]['long_answer']['end_token']\n",
    "\" \".join(x[\"document_text\"].split(\" \")[start_token:end_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30d055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = json.loads(list_of_q[0])\n",
    "start_token = x['annotations'][0]['short_answers'][0]['start_token']\n",
    "end_token = x['annotations'][0]['short_answers'][0]['end_token']\n",
    "\" \".join(x[\"document_text\"].split(\" \")[start_token:end_token])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432087b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \" \".join(x[\"document_text\"].split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6944f1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = get_paragraphs(x['document_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c79a810",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QA('model')\n",
    "# model.predict([t,t],[x['question_text'],x['question_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd955f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://wikipedia.org/w/api.php\"\n",
    "INDEX_URL = \"https://wikipedia.org/w/index.php\"\n",
    "\n",
    "def get_wikipedia_revision(title, date, diagnostic=False):\n",
    "    session = requests.Session()\n",
    "    parameters = {\n",
    "        \"action\": \"query\",\n",
    "        \"prop\": \"revisions\",\n",
    "        \"titles\": title,\n",
    "        \"rvprop\": \"ids|timestamp|comment\",\n",
    "        \"rvslots\": \"main\",\n",
    "        \"rvstart\": date.isoformat(),\n",
    "        \"rvlimit\": \"1\",\n",
    "        \"formatversion\" : \"2\",\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "#     print(parameters)\n",
    "    revision_response = session.get(url=API_URL, params=parameters)\n",
    "    revision_response.raise_for_status()\n",
    "    \n",
    "    # revision data succeeded\n",
    "    revision_data = revision_response.json()\n",
    "#     print(revision_data)\n",
    "    try:\n",
    "        parameters = {\n",
    "#             \"title\" : title,\n",
    "            \"oldid\" : revision_data['query']['pages'][0]['revisions'][0]['revid']\n",
    "        }\n",
    "    except (IndexError,KeyError) as e:\n",
    "        if not diagnostic:\n",
    "            return None, None\n",
    "        else:\n",
    "            raise e\n",
    "#     print(parameters)\n",
    "    page_response = session.get(url=INDEX_URL, params=parameters)\n",
    "#     return page_response\n",
    "    return page_response.text, page_response.url\n",
    "    \n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ce3624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_short_answers_train_set(question):\n",
    "    answers = []\n",
    "    for an in question['annotations']:\n",
    "        if len(an['short_answers']) > 0:\n",
    "            for sa in an['short_answers']:\n",
    "                start_token = sa['start_token']\n",
    "                end_token = sa['end_token']\n",
    "                answ_text = \" \".join(question[\"document_text\"].split(\" \")[start_token:end_token])\n",
    "                answers.append(answ_text)\n",
    "                \n",
    "    \n",
    "    return set(answers)\n",
    "        \n",
    "def get_paragraphs(text):\n",
    "#     print(text)\n",
    "    if text is not None:\n",
    "        soup = BeautifulSoup(text)\n",
    "    # document_text = \" \".join(t.text for t in soup.find_all('p'))\n",
    "        for div in soup.find_all(\"div\", {'class':'mw-revision warningbox'}): \n",
    "            div.decompose()\n",
    "        document_text = \" \".join(t.text for t in soup.find_all('p')[:25])\n",
    "        return document_text\n",
    "    else: \n",
    "        return None\n",
    "    \n",
    "def get_long_answers(question):\n",
    "    answers = []\n",
    "    for annotation in question['annotations']:\n",
    "        if len(annotation['long_answer']) != 0:\n",
    "            short_answer = annotation['long_answer']\n",
    "#             print(short_answer)\n",
    "            start_token = short_answer['start_token']\n",
    "            end_token = short_answer['end_token']\n",
    "#             print(question['document_tokens'][start_token:end_token])\n",
    "            a = \" \".join(t['token'] for t in question['document_tokens'][start_token:end_token] if not t['html_token'])\n",
    "            if a != '':\n",
    "                answers.append(a)\n",
    "#         else:\n",
    "#             print('No short answers found in annotation.')\n",
    "            \n",
    "    return set(answers)\n",
    "\n",
    "def get_short_answers(question):\n",
    "    answers = []\n",
    "    for annotation in question['annotations']:\n",
    "        if len(annotation['short_answers']) != 0:\n",
    "            short_answer = annotation['short_answers'][0]\n",
    "#             print(short_answer)\n",
    "            start_token = short_answer['start_token']\n",
    "            end_token = short_answer['end_token']\n",
    "#             print(question['document_tokens'][start_token:end_token])\n",
    "            a = \" \".join(t['token'] for t in question['document_tokens'][start_token:end_token])\n",
    "            answers.append(a)\n",
    "#         else:\n",
    "#             print('No short answers found in annotation.')\n",
    "            \n",
    "    return set(answers)\n",
    "\n",
    "\n",
    "def get_all_revs(question, display = False):\n",
    "    compares = {}\n",
    "    x = json.loads(question)\n",
    "#     sa = get_short_answers(x).union(get_long_answers(x))\n",
    "    sa = get_short_answers_train_set(x)\n",
    "    if sa == set():\n",
    "        print(\"i am sad\")\n",
    "        return [None] * 3\n",
    "#     print(len(sa), x)\n",
    "\n",
    "    qtext = x[\"question_text\"]\n",
    "    title = x[\"document_url\"][x[\"document_url\"].index(\"title\")+6:x[\"document_url\"].index(\"&amp\")]\n",
    "#     title = x['document_title']\n",
    "#     dates = [datetime.datetime(2008,1,1),datetime.datetime(2010,1,1),datetime.datetime(2012,1,1),datetime.datetime(2014,1,1),datetime.datetime(2016,1,1),datetime.datetime(2018,1,1), datetime.datetime.now()]\n",
    "#     dates = [datetime.datetime(2010,1,1),datetime.datetime(2014,1,1),datetime.datetime(2018,1,1), datetime.datetime.now()]\n",
    "    dates = [datetime.datetime(2008,1,1),datetime.datetime(2012,1,1),datetime.datetime(2016,1,1)]\n",
    "\n",
    "    ret = [\"\", qtext]\n",
    "    col_names = [\"GT Answers\", \"Question\"]\n",
    "    if display:\n",
    "        print(title)\n",
    "#     document_html = \" \".join(t['token'] for t in x['document_tokens'])\n",
    "    document_html = \" \".join(x[\"document_text\"].split(\" \"))\n",
    "    document_text = get_paragraphs(document_html)\n",
    "    if display:\n",
    "        print('\\nFor Original:')\n",
    "    avg, sets, sort, _, ans, pred, _ = compare(qtext, document_text, sa, display) #['Average Score', 'Set Score', 'Sort Score','Question', 'Answer', 'Predicted', 'Length of Text'])\n",
    "    if ans not in ret[0]:\n",
    "        ret[0] = ret[0] + ans + \" -- \"    \n",
    "    ret.extend([avg, pred])\n",
    "    col_names.append(\"Avg Score: original\")\n",
    "    col_names.append(\"Prediction: original\")     \n",
    "    \n",
    "    all_avg = 0\n",
    "    i = 0\n",
    "    l_doc = []\n",
    "    l_doc.append(document_text)\n",
    "    for d in dates:\n",
    "        if display:\n",
    "            print('\\nFor date: ', d)\n",
    "        doctext, _ = get_wikipedia_revision(title, d, diagnostic = False)\n",
    "        doctext = get_paragraphs(doctext)\n",
    "        avg = 0\n",
    "        pred = \"No Edit\"\n",
    "        if doctext is not None:\n",
    "            l_doc.append(doctext)\n",
    "            avg, sets, sort, _, ans, pred, _ = compare(qtext, doctext, sa, display) #['Average Score', 'Set Score', 'Sort Score','Question', 'Answer', 'Predicted', 'Length of Text'])\n",
    "            if ans not in ret[0]:\n",
    "                ret[0] = ret[0] + ans + \" -- \"\n",
    "            i = i + 1   \n",
    "        ret.extend([avg, pred])\n",
    "        all_avg += avg\n",
    "        col_names.append(\"Avg Score: \" + str(d))\n",
    "        col_names.append(\"Predicted: \" + str(d))\n",
    "        \n",
    "    if i == 0: \n",
    "        ret.insert(0, np.nan)\n",
    "    else:\n",
    "        ret.insert(0, all_avg/i)\n",
    "        \n",
    "    col_names.insert(0, \"Overall Avg\")\n",
    "    return ret, col_names, l_doc\n",
    "\n",
    "\n",
    "def compare(qtext, doctext, short_answers, display = False):\n",
    "\n",
    "    question_text = qtext\n",
    "    if display:\n",
    "        print('Question: ', question_text)\n",
    "    doc = doctext\n",
    "    q = question_text\n",
    "    answer = model.predict(doc,q)\n",
    "    if display:\n",
    "        print('Predicted Answer: ', answer['answer'])\n",
    "    \n",
    "    set_scores = [-1]\n",
    "    sort_scores = [-1]\n",
    "    all_avg_scores = [-1]\n",
    "    for sa in short_answers:\n",
    "        token_set_ratio = fuzz.token_set_ratio(sa, answer['answer'])\n",
    "        token_sort_ratio = fuzz.token_sort_ratio(sa, answer['answer'])\n",
    "        avg_score = (token_set_ratio + token_sort_ratio) / 2\n",
    "        if display:\n",
    "            print('Correct Answer: ', sa)\n",
    "            print('Fuzzy score: ', avg_score)\n",
    "        set_scores.append(token_set_ratio)\n",
    "        sort_scores.append(token_sort_ratio)\n",
    "        all_avg_scores.append(avg_score)\n",
    "    if len(short_answers) == 0:\n",
    "        short_answers = [None]\n",
    "    max_index = all_avg_scores.index(max(all_avg_scores)) - 1\n",
    "    return (max(all_avg_scores), max(set_scores), max(sort_scores), question_text, list(short_answers)[max_index], answer['answer'], len(doctext))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1746fbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many have no short answers\n",
    "# ind = []\n",
    "# for i in range(len(list_of_q)):\n",
    "#     l = list_of_q[i]\n",
    "#     x = json.loads(l)\n",
    "#     short_ans = get_short_answers(x)\n",
    "#     if len(short_ans) != 0:\n",
    "#         ind.append(i)\n",
    "\n",
    "\n",
    "ind = []\n",
    "for i in tqdm(range(len(list_of_q))):\n",
    "    l = list_of_q[i]\n",
    "    x = json.loads(l)\n",
    "    s_ans = get_short_answers_train_set(x)\n",
    "    if s_ans != set():\n",
    "        ind.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaeb4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e761cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ret, col_names, l_doc = get_all_revs(list_of_q[2], display = True)\n",
    "x = json.loads(list_of_q[ind[4]])\n",
    "get_short_answers_train_set(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d39a295",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# rows = []\n",
    "# for q in tqdm(list_of_q):\n",
    "#     try:\n",
    "#         row, cols, l_doc = get_all_revs(q)\n",
    "#     except:\n",
    "#         continue\n",
    "#     if cols is not None:\n",
    "#         good_cols = cols\n",
    "#     if row is not None:\n",
    "#         rows.append(row)\n",
    "        \n",
    "    \n",
    "# scoress = pd.DataFrame(rows, columns = good_cols).sort_values(['Overall Avg'], ascending = False)\n",
    "\n",
    "\n",
    "rows = []\n",
    "for i in tqdm(ind[0:20000]):\n",
    "    try:\n",
    "        row, cols, l_doc = get_all_revs(list_of_q[i])\n",
    "    except:\n",
    "        break\n",
    "    if cols is not None:\n",
    "        good_cols = cols\n",
    "    if row is not None:\n",
    "        rows.append(row)\n",
    "        \n",
    "    \n",
    "scoress = pd.DataFrame(rows, columns = good_cols).sort_values(['Overall Avg'], ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a668eb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoress.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0542f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoress.to_csv('scores_short_answer_only_0_20k_new_dates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe1ccee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# t,u = get_wikipedia_revision('Benjamin_Stone_(Law_&_Order_character)', datetime.datetime.now(), diagnostic = True)\n",
    "\n",
    "\n",
    "scoress = pd.read_csv('scores_short_answer_only_10k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b22634",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get_paragraphs(t)\n",
    "# print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0585e6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl -X GET https://en.wikipedia.org/w/api.php?action=query&prop=revisions&titles=Therefore_sign&rvprop=ids%7Ctimestamp%7Ccomment&rvslots=main&rvstart=2021-04-21T22%3A29%3A08.802494&rvlimit=1&formatversion=2&format=json\n",
    "    \n",
    "    \n",
    "scoress.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b65dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime.datetime(2013,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc41bf55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scoress[scoress['Avg Score: original'] > 70].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d55f90",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scoress[scoress['Avg Score: original'] > 70].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eec078",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scoress[scoress['Avg Score: original'] > 70].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3def0074",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoress.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cd1f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoress[scoress.isin(['No Edit']).any(axis=1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e963f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoress[scoress.isin(['Redirect']).any(axis=1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630e8d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoress[~scoress.isin(['Redirect', 'No Edit']).any(axis=1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aada2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = scoress[~scoress.isin(['Redirect', 'No Edit']).any(axis=1)]\n",
    "s = s[s['Avg Score: original'] > 70]\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f61a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for i in list_of_q:\n",
    "    x = json.loads(i)\n",
    "    rows.append([x[\"question_text\"], x[\"document_title\"]])\n",
    "    \n",
    "titles = pd.DataFrame(rows, columns = [\"Question\", \"Wiki Page\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f43576",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a05afd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
